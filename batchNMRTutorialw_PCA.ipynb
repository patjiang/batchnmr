{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patjiang/batchnmr/blob/main/batchNMRTutorialw_PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Begin by importing data\n",
        "\n",
        "Because NMR files and the overall file format in general is in a nested directory-type format, you need to zip your files while they are in this format:\n",
        "\n",
        "```bash\n",
        "file_dir/\n",
        "├── sample name/condition (1)\n",
        "├    ├── key (1)\n",
        "├    └── key (2)\n",
        "├── sample name/condition (2)\n",
        "├    ├── key (1)\n",
        "├    └── key (2)\n",
        "├── sample name/condition (3)\n",
        "├    ├── key (1)\n",
        "├    └── key (2)\n",
        "└──sample name/condition (4)\n",
        "     ├── key (1)\n",
        "     └── key (2)\n",
        "```\n",
        "\n",
        "## For Example:\n",
        "```bash\n",
        "brain_run_12-13-23/\n",
        "├──  Brain organoid - Control\n",
        "├    ├── lipid\n",
        "├    └── water\n",
        "└──  Brain organoid - microglia\n",
        "     ├── lipid\n",
        "     └── water\n",
        "```\n",
        "Then, within each \"key\" folder, you should have the actual NMR file scans, like:\n",
        "\n",
        "```bash\n",
        "water/\n",
        "  ├──experiment name1\n",
        "  ├   └── 10\n",
        "  ├      ├── acqus\n",
        "  ├      ├── fid\n",
        "  ├      ├── acqu\n",
        "  ├      └── pdata\n",
        "  ├           └── 1\n",
        "  ├               ├── 1r\n",
        "  ├               ├── 1i\n",
        "  ├               ├── proc\n",
        "  ├               └── procs\n",
        "  └──experiment name2\n",
        "      └── 10\n",
        "         ├── acqus\n",
        "         ├── fid\n",
        "         ├── acqu\n",
        "         └── pdata\n",
        "              └── 1\n",
        "                  ├── 1r\n",
        "                  ├── 1i\n",
        "                  ├── proc\n",
        "                  └── procs\n",
        "```\n"
      ],
      "metadata": {
        "id": "FH-8TpohuMlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title import dependencies and set up venv\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "\n",
        "os.system(\"pip install git+https://github.com/NMRPy/nmrpy.git@4aeb0b738b72743900b45cfc9e7f8caaa3381b20\")\n",
        "os.system(\"pip install PyWavelets\")\n",
        "import nmrpy\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "from matplotlib import colormaps\n",
        "import pywt\n",
        "\n",
        "def import_data(file_dir, key):\n",
        "    init_arr = os.listdir(f\"./{file_dir}/\")\n",
        "\n",
        "    exp_names = []\n",
        "    for i in range(len(init_arr)):\n",
        "        if(\".\" not in init_arr[i]):\n",
        "            exp_names.append(init_arr[i])\n",
        "\n",
        "    fidarr_dict = {}\n",
        "    for j in range(len(exp_names)):\n",
        "        file_arr = os.listdir(f\"./{file_dir}/{exp_names[j]}/{key}/\")\n",
        "        temp_dict = {}\n",
        "        for k in range(len(file_arr)):\n",
        "            if(\".\" not in file_arr[k]):\n",
        "                temp_dict[file_arr[k]] = nmrpy.from_path(fid_path=f\"./{file_dir}/{exp_names[j]}/{key}/{file_arr[k]}\")\n",
        "                print(f\"./{file_dir}/{exp_names[j]}/{key}/{file_arr[k]}\")\n",
        "        fidarr_dict[f\"{exp_names[j]}\"] = temp_dict\n",
        "\n",
        "    return fidarr_dict\n",
        "\n",
        "def preprocess(fid_array: nmrpy.data_objects.FidArray):\n",
        "    start_time = time.time()\n",
        "    print(\"EMHZ, Fourier Transform\")\n",
        "    em_ft(fid_array)\n",
        "    print(\"Finished!\\nPhase Correct, Real, Norm Fids:\\n\")\n",
        "    pc(fid_array)\n",
        "    print(\"Finished!\")\n",
        "    print(\"-- %5.5f s Run Time --\" % (time.time() - start_time))\n",
        "\n",
        "def em_ft(fid_array: nmrpy.data_objects.FidArray):\n",
        "    fid_array.emhz_fids();\n",
        "    fid_array.ft_fids();\n",
        "\n",
        "def pc(fid_array: nmrpy.data_objects.FidArray):\n",
        "    fid_array.phase_correct_fids(verbose = False);\n",
        "    fid_array.real_fids();\n",
        "    fid_array.norm_fids();\n",
        "\n",
        "def generate_idx(n, arr):\n",
        "    m = len(arr)\n",
        "    out = []\n",
        "    for i in range(n):\n",
        "        n = str(np.random.randint(0,m))\n",
        "        while(n in out):\n",
        "            n = str(np.random.randint(0,m))\n",
        "        s = str(n)\n",
        "        while(len(s) != len(str(m))):\n",
        "            s = \"0\" + s\n",
        "        out.append(s)\n",
        "    return out\n",
        "\n",
        "def avg_spectra(fidArray: nmrpy.data_objects.FidArray, n):\n",
        "    dataOut = 0\n",
        "    ppmOut = 0\n",
        "    indx_array = generate_idx(n, fidArray.data)\n",
        "    #print(indx_array)\n",
        "    for i in range(n):\n",
        "        dataOut = dataOut + fidArray.get_fid(f\"fid{indx_array[i]}\").data\n",
        "        ppmOut = ppmOut + fidArray.get_fid(f\"fid{indx_array[i]}\")._ppm\n",
        "    dataOut = dataOut / n\n",
        "    ppmOut = ppmOut / n\n",
        "    return dataOut, ppmOut\n",
        "\n",
        "def fidDictViz(dataDict):\n",
        "    if type(dataDict) is dict:\n",
        "        for i in dataDict.keys():\n",
        "            print(f\"{i}:\")\n",
        "            print(f\"\\t{fidDictViz(dataDict[i])}\")\n",
        "    #type(a) is nmrpy.data_objects.FidArray\n",
        "        return \"\"\n",
        "    elif type(dataDict) is np.ndarray:\n",
        "        print(f\"\\t{dataDict}\")\n",
        "        return \"\"\n",
        "    else:\n",
        "        if(len(dataDict.get_fids()) > 10):\n",
        "            print(f\"\\t{[f.id for f in dataDict.get_fids()[1:5]]}, {len(dataDict.get_fids()) - 4} keys omitted\")\n",
        "        else:\n",
        "            print(f\"\\t{[f.id for f in dataDict.get_fids()]}\")\n",
        "        return \"\"\n",
        "\n",
        "def preproc_max_inDict(dataDict):\n",
        "    for i in dataDict.keys():\n",
        "        tAvg = {}\n",
        "        tPpm = {}\n",
        "        for j in dataDict[i].keys():\n",
        "            preprocess(dataDict[i][j])\n",
        "            tTuple = avg_spectra(dataDict[i][j], len(dataDict[i][j].data))\n",
        "            tAvg[j] = tTuple[0]\n",
        "            tPpm[j] = tTuple[1]\n",
        "        dataDict[i][\"max_avgs\"] = tAvg\n",
        "        dataDict[i][\"max_ppms\"] = tPpm\n",
        "\n",
        "def plotmaxDict(dataDict, samples, cmap = 'viridis'):\n",
        "    map = matplotlib.colormaps[cmap].resampled(samples)\n",
        "    counter = 0\n",
        "    for i in dataDict.keys():\n",
        "        for j in dataDict[i][\"max_avgs\"].keys():\n",
        "            plt.plot(dataDict[i][\"max_ppms\"][j], dataDict[i][\"max_avgs\"][j],\n",
        "                     c = map.colors[counter],\n",
        "                     label = f\"{i}_{j}\")\n",
        "            counter += 1\n",
        "    plt.legend()\n",
        "    plt.xlim(left = -1, right = 6)\n",
        "\n",
        "def shift_lip(fid_arr, ppm, verbose):\n",
        "  pos = np.where(fid_arr == max(fid_arr))\n",
        "  top = np.where((ppm == 8 + min([abs(x - 8) for x in ppm])) | (ppm == 8 - min([abs(x - 8) for x in ppm])))\n",
        "  shift = True\n",
        "  if(pos != top):\n",
        "      if verbose:\n",
        "          print(f\"\\tPosition Not Equal: \\tfidpos: {pos[0][0]}\\tppmpos: {top[0][0]}, \\tppm value: {ppm[top[0][0]]}\\n\")\n",
        "  else:\n",
        "      if verbose:\n",
        "          print(f\"\\tPosition Equal: \\tfidpos: {pos[0][0]}\\tppmpos: {top[0][0]}, \\tppm value: {ppm[top[0][0]]}\\n\")\n",
        "      shift = False\n",
        "      newFID = fid_arr\n",
        "\n",
        "  if shift:\n",
        "      if verbose:\n",
        "          print(\"\\tShifting fid such that the highest frequency peak is also closest to 8\\n\")\n",
        "      diff = top[0][0] - pos[0][0]\n",
        "      if verbose:\n",
        "          print(f\"\\tShift amount = {diff}\\n\")\n",
        "      if (diff > (len(fid_arr)/10)):\n",
        "          if verbose:\n",
        "              print(\"\\tToo much shift. Alignment Failed\\n\")\n",
        "          return \"emp\",\"ty\"\n",
        "      else:\n",
        "          newFID = np.roll(fid_arr, diff)\n",
        "          shift_lip(newFID, ppm, verbose = verbose)\n",
        "\n",
        "  #set min ppm to 0\n",
        "\n",
        "  ppmval = ppm[top]\n",
        "\n",
        "  new_ppm = 8 - ppmval + ppm\n",
        "\n",
        "  pos = np.where(newFID == max(newFID))\n",
        "  top = np.where((new_ppm == 8 + min([abs(x-8) for x in new_ppm])) | (new_ppm == 8 - min([abs(x-8) for x in new_ppm])))\n",
        "\n",
        "  if verbose:\n",
        "      print(f\"final values: \\tfidpos: {pos[0][0]}\\tppmpos: {top[0][0]}, \\tppm value: {new_ppm[top[0][0]]}\\n\")\n",
        "\n",
        "  return newFID, new_ppm\n",
        "\n",
        "def shift_tms(fid_arr, ppm, verbose):\n",
        "    pos = np.where(fid_arr == max(fid_arr))\n",
        "    zero = np.where((ppm == min(abs(ppm))) | (ppm == -1 * min(abs(ppm))))\n",
        "    shift = True\n",
        "    if(pos != zero):\n",
        "        if verbose:\n",
        "            print(f\"\\tPosition Not Equal: \\tfidpos: {pos[0][0]}\\tppmpos: {zero[0][0]}, \\tppm value: {ppm[zero[0][0]]}\\n\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"\\tPosition Equal: \\tfidpos: {pos[0][0]}\\tppmpos: {zero[0][0]}, \\tppm value: {ppm[zero[0][0]]}\\n\")\n",
        "        shift = False\n",
        "        newFID = fid_arr\n",
        "\n",
        "    if shift:\n",
        "        if verbose:\n",
        "            print(\"\\tShifting fid such that the highest frequency peak is also closest to 0\\n\")\n",
        "        diff = zero[0][0] - pos[0][0]\n",
        "        if verbose:\n",
        "            print(f\"\\tShift amount = {diff}\\n\")\n",
        "        if (diff > (len(fid_arr)/10)):\n",
        "            if verbose:\n",
        "                print(\"\\tToo much shift. Alignment Failed\\n\")\n",
        "            return \"emp\",\"ty\"\n",
        "        else:\n",
        "            newFID = np.roll(fid_arr, diff)\n",
        "            shift_tms(newFID, ppm, verbose = verbose)\n",
        "\n",
        "    #set min ppm to 0\n",
        "\n",
        "    ppmval = ppm[zero]\n",
        "\n",
        "    new_ppm = ppm - ppmval\n",
        "\n",
        "    pos = np.where(newFID == max(newFID))\n",
        "    zero = np.where((new_ppm == min(abs(new_ppm))) | (new_ppm == -1 * min(abs(new_ppm))))\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"final values: \\tfidpos: {pos[0][0]}\\tppmpos: {zero[0][0]}, \\tppm value: {new_ppm[zero[0][0]]}\\n\")\n",
        "\n",
        "    return newFID, new_ppm\n",
        "\n",
        "def rem_invalid_shift_dict(shift, ppmSh):\n",
        "    nshift = dict(shift)\n",
        "    nppmSh = dict(ppmSh)\n",
        "    for i in shift.keys():\n",
        "        if type(nshift[i]) == str:\n",
        "            del nshift[i]\n",
        "            del nppmSh[i]\n",
        "    return nshift, nppmSh\n",
        "\n",
        "def calc_shift_dict(dataDict, typ, verbose = True):\n",
        "    for i in dataDict.keys():\n",
        "        tshift = {}\n",
        "        tppms = {}\n",
        "        for j in dataDict[i][\"max_avgs\"].keys():\n",
        "          if(typ == \"water\"):\n",
        "            tTuple = (shift_tms(dataDict[i][\"max_avgs\"][j], dataDict[i][\"max_ppms\"][j], verbose = verbose))\n",
        "            tshift[j] = tTuple[0]\n",
        "            tppms[j] = tTuple[1]\n",
        "          elif(typ == \"lipid\"):\n",
        "            tTuple = (shift_lip(dataDict[i][\"max_avgs\"][j], dataDict[i][\"max_ppms\"][j], verbose = verbose))\n",
        "            tshift[j] = tTuple[0]\n",
        "            tppms[j] = tTuple[1]\n",
        "          else:\n",
        "            print(\"Invalid Type\")\n",
        "        tshift, tppms = rem_invalid_shift_dict(tshift, tppms)\n",
        "        dataDict[i][\"shift\"] = tshift\n",
        "        dataDict[i][\"ppmSh\"] = tppms\n",
        "\n",
        "def plotshiftDict(dataDict, samples, cmap = 'viridis'):\n",
        "    map = matplotlib.colormaps[cmap].resampled(samples)\n",
        "    counter = 0\n",
        "    for i in dataDict.keys():\n",
        "        for j in dataDict[i][\"shift\"].keys():\n",
        "            plt.plot(dataDict[i][\"ppmSh\"][j], dataDict[i][\"shift\"][j],\n",
        "                     c = map.colors[counter],\n",
        "                     label = f\"{i}_{j}\")\n",
        "            counter += 1\n",
        "    plt.legend()\n",
        "    plt.xlim(left = -1, right = 6)\n",
        "\n",
        "\n",
        "def closer_to_zero(spec, ppm):\n",
        "    cond = False\n",
        "    max_index = np.where(spec == max(spec))[0][0]\n",
        "    if(abs(ppm[max_index]) < (1 - abs(ppm[max_index]))):\n",
        "        cond = True\n",
        "    return cond\n",
        "\n",
        "def focus_ppm_region(spec, ppm):\n",
        "    #truncate TMS peak and water suppression peak\n",
        "    tempSpec = np.array(spec)\n",
        "    index_of_TMS = np.where(tempSpec == max(tempSpec))[0][0]\n",
        "    index_of_water = np.where(tempSpec == min(spec))[0][0]\n",
        "    return spec[index_of_water: index_of_TMS], ppm[index_of_water:index_of_TMS]\n",
        "\n",
        "def repad(spec, ppm, n, max = True):\n",
        "    tspec = spec\n",
        "    tppm = ppm\n",
        "    if max:\n",
        "        if(len(tspec) < n):\n",
        "            tspec = np.pad(tspec, (0, n - len(tspec)))\n",
        "            tppm = np.pad(tppm, (0, n - len(tppm)))\n",
        "    else:\n",
        "        if(len(spec) > n):\n",
        "            tspec = tspec[:(n - len(tspec))]\n",
        "            tppm = tppm[:(n - len(tppm))]\n",
        "\n",
        "    return tspec, tppm\n",
        "\n",
        "\n",
        "def truncate_dict(dataDict, bymax = True):\n",
        "    if(bymax):\n",
        "        nlen = 0\n",
        "    else:\n",
        "        nlen = math.inf\n",
        "    for i in dataDict.keys():\n",
        "        trun = {}\n",
        "        tppm = {}\n",
        "        for j in dataDict[i][\"shift\"]:\n",
        "            #print(f\"Truncating shifted spectra in {j}\")\n",
        "            trun[j] = dataDict[i][\"shift\"][j]\n",
        "            tppm[j] = dataDict[i][\"ppmSh\"][j]\n",
        "            while(closer_to_zero(trun[j], tppm[j])):\n",
        "                tTuple = focus_ppm_region(trun[j], tppm[j])\n",
        "                trun[j] = tTuple[0]\n",
        "                tppm[j] = tTuple[1]\n",
        "            if(len(trun[j]) > nlen) and bymax:\n",
        "                nlen = len(trun[j])\n",
        "            elif(len(trun[j]) < nlen) and not bymax:\n",
        "                nlen = len(trun[j])\n",
        "        dataDict[i][\"truncated\"] = trun\n",
        "        dataDict[i][\"tPpm\"] = tppm\n",
        "    #print(nlen)\n",
        "\n",
        "    for i in dataDict.keys():\n",
        "        for k in dataDict[i][\"truncated\"].keys():\n",
        "            dataDict[i][\"truncated\"][k], dataDict[i][\"tPpm\"][k] = repad(dataDict[i][\"truncated\"][k], dataDict[i][\"tPpm\"][k], n = nlen, max = bymax)\n",
        "            #print(len(dataDict[i][\"truncated\"][k]), len(dataDict[i][\"tPpm\"][k]))\n",
        "\n",
        "def plotTruncdict(dataDict, samples, cmap = 'viridis'):\n",
        "    map = matplotlib.colormaps[cmap].resampled(samples)\n",
        "    counter = 0\n",
        "    for i in dataDict.keys():\n",
        "        for j in dataDict[i][\"truncated\"].keys():\n",
        "            #print(len(dataDict[i][\"tPpm\"][j]), len(dataDict[i][\"tPpm\"][j]))\n",
        "            plt.plot(dataDict[i][\"tPpm\"][j], dataDict[i][\"truncated\"][j],\n",
        "                     c = map.colors[counter],\n",
        "                     label = f\"{i}_{j}\")\n",
        "            counter += 1\n",
        "    plt.legend()"
      ],
      "metadata": {
        "id": "J5r1ZccJyq5D",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import data and unzip into colab environment. This may take a while so please let it run in the background!\n",
        "from google.colab import files\n",
        "\n",
        "uploader =  files.upload()\n",
        "zipfile = uploader[list(uploader.keys())[0]]\n",
        "\n",
        "with open(\"input.zip\",\"wb\") as out: out.write(zipfile)\n",
        "\n",
        "!unzip -q input.zip\n",
        "!rm input.zip\n",
        "!rm -r __MACOSX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "irmf2rMnuMRY",
        "outputId": "a05788b7-d722-483e-8036-22dd2212bb78",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-26d4a8d1-7bff-49bf-ae33-e95d10451007\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-26d4a8d1-7bff-49bf-ae33-e95d10451007\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-40aaa7bae9fd>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0muploader\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mzipfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muploader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input.zip\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import and preprocess into the working environment\n",
        "dir = \"AAStandards-formatted\" #@param {type:\"string\"}\n",
        "key = \"buf\" #@param {type:\"string\"}\n",
        "dataDict = import_data(dir, key)\n",
        "preproc_max_inDict(dataDict)"
      ],
      "metadata": {
        "id": "sKJMBqzx1sLK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot the figures\n",
        "plt.figure(figsize=(16,8))\n",
        "plotmaxDict(dataDict, 15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oAkw11WB2AaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "dD = copy.deepcopy(dataDict)\n",
        "plt.figure(figsize=(16,8))\n",
        "plotmaxDict(dD, 16)\n",
        "plt.xlim(-1, 10)\n",
        "plt.show()\n",
        "for i in dD.keys():\n",
        "  keylist = dD[i][\"max_ppms\"].keys()\n",
        "  for j in keylist:\n",
        "    tarr = dD[i][\"max_ppms\"][j]\n",
        "    narr = np.array([(8-x) for x in tarr])\n",
        "    dD[i][\"max_ppms\"][j] = narr\n",
        "plt.figure(figsize=(16,8))\n",
        "plotmaxDict(dD, 16)\n",
        "plt.xlim(-1, 10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YjxrIcmQ2uaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title DANGER DO NOT RUN\n",
        "aware = True #@param {type: \"boolean\"}\n",
        "sample_num = 8 #@param {type: \"integer\"}\n",
        "include_limit = True #@param {type:\"boolean\"}\n",
        "xleft_limit = -1 #@param {type:\"integer\"}\n",
        "xright_limit = 10 #@param {type:\"integer\"}\n",
        "\n",
        "title = \"pseudo lip sample\" #@param {type:\"string\"}\n",
        "title_size = 16 #@param {type:\"integer\"}\n",
        "xlabel = \"ppm\" #@param {type:\"string\"}\n",
        "ylabel = \"arbitrary intensity\" #@param {type:\"string\"}\n",
        "nmr_type = \"lipid\" #@param ['water', 'lipid']\n",
        "\n",
        "if aware:\n",
        "  calc_shift_dict(dD, nmr_type, verbose = True)\n",
        "  plt.figure(figsize=(16,8))\n",
        "  plotshiftDict(dD, sample_num, cmap = 'plasma')\n",
        "  if(include_limit):\n",
        "    plt.xlim(xleft_limit,xright_limit)\n",
        "\n",
        "  plt.title(title, fontsize = title_size)\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.ylabel(ylabel)\n",
        "  plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "BKGVwdeOzVtE",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Shift the spectra and plot\n",
        "colormap = 'turbo' #@param {type:\"string\"}\n",
        "sample_num = 15 #@param {type: \"integer\"}\n",
        "include_limit = False #@param {type:\"boolean\"}\n",
        "xleft_limit = 2 #@param {type:\"integer\"}\n",
        "xright_limit = 4 #@param {type:\"integer\"}\n",
        "\n",
        "title = \"water samples split brain\" #@param {type:\"string\"}\n",
        "title_size = 16 #@param {type:\"integer\"}\n",
        "xlabel = \"ppm\" #@param {type:\"string\"}\n",
        "ylabel = \"arbitrary intensity\" #@param {type:\"string\"}\n",
        "nmr_type = \"water\" #@param ['water', 'lipid']\n",
        "\n",
        "calc_shift_dict(dataDict, nmr_type, verbose = False)\n",
        "plt.figure(figsize=(16,8))\n",
        "plotshiftDict(dataDict, sample_num, cmap = colormap)\n",
        "if(include_limit):\n",
        "  plt.xlim(xleft_limit,xright_limit)\n",
        "\n",
        "plt.title('Bold Figure Title', weight='bold')\n",
        "plt.title(title, fontsize = title_size)\n",
        "plt.xlabel(xlabel)\n",
        "plt.ylabel(ylabel)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8UqUn4KA24Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_nparray(list_of_dicts, exp):\n",
        "  ou = []\n",
        "  la = []\n",
        "  if exp:\n",
        "    for i in list_of_dicts:\n",
        "      exp_list = list(i[list(i.keys())[0]].keys())\n",
        "      for j in exp_list:\n",
        "        ou.append(i[list(i.keys())[0]][j])\n",
        "        la.append(j)\n",
        "    return ou, la\n",
        "  else:\n",
        "    for i in list_of_dicts:\n",
        "      cond = list(i.keys())[0]\n",
        "      for j in list(i[list(i.keys())[0]].keys()):\n",
        "        ou.append(i[list(i.keys())[0]][j])\n",
        "        la.append(cond)\n",
        "    return ou, la\n",
        "\n",
        "\n",
        "\n",
        "def extract_shifted_data(df, exp = True):\n",
        "  out = []\n",
        "  labels = list(df.keys())\n",
        "  for i in labels:\n",
        "    experiments = df[i]['shift'].keys()\n",
        "    tmp = {}\n",
        "    for j in experiments:\n",
        "      tmp.update({j : df[i]['shift'][j]})\n",
        "    out.append({i: tmp})\n",
        "  return to_nparray(out, exp = exp)\n",
        "  #return out\n",
        "\n",
        "shifted, labels = extract_shifted_data(dataDict, exp = True)\n",
        "#shifted= extract_shifted_data(dataDict)"
      ],
      "metadata": {
        "id": "s8mc6cwHK053"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Perform a PCA on the data\n",
        "pca = PCA(n_components=2)\n",
        "principalComponents = pca.fit_transform(shifted)\n",
        "exp = pca.explained_variance_\n",
        "\n",
        "principalDf = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2'])\n",
        "principalDf['labels'] = labels\n",
        "s = 4\n",
        "fig = plt.figure(figsize = (s,s))\n",
        "ax = fig.add_subplot(1,1,1)\n",
        "ax.set_xlabel(f'Principal Component 1 - Explained Variance: {round(exp[0], 2)}', fontsize = 2*s)\n",
        "ax.set_ylabel(f'Principal Component 2 - Explained Variance: {round(exp[1], 2)}', fontsize = 2*s)\n",
        "ax.set_title('2 component PCA', fontsize = 3*s)\n",
        "#input labels here!\n",
        "#also change the colors!\n",
        "labels = ['1mm', '1_5mm', '2mm']\n",
        "colors = ['r', 'g', 'b']\n",
        "for label, color in zip(labels,colors):\n",
        "    indicesToKeep = [label in x for x in principalDf['labels']]\n",
        "    ax.scatter(principalDf.loc[indicesToKeep, 'PC1'], principalDf.loc[indicesToKeep, 'PC2'], c = color, s = 25)\n",
        "ax.legend(labels, loc='best')\n",
        "ax.grid()"
      ],
      "metadata": {
        "id": "NTkVTMg-ORF-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}